# Варіант 6. Побудова лінійної регресійної моделі для прогнозування значень
## Вивід у консоль

Після виконання коду отримуємо наступний вивід:  
Коефіцієнти моделі:
Feature1: 0.5770
Feature2: 0.8658
Feature3: -0.4326
Feature4: 0.0288
Feature5: 0.0288
Feature6: 0.0291
Feature7: 0.0288
Feature8: 0.0289
Feature9: 0.0288
Feature10: 0.0289
Feature11: 0.0288
Feature12: 0.0289
Feature13: 0.0288
Feature14: 0.0289
Feature15: 0.0288
Feature16: 0.0287
Feature17: 0.0289
Feature18: 0.0288
Feature19: 0.0288
Feature20: 0.0289
Feature21: 0.0288
Feature22: 0.0287
Feature23: 0.0289
Feature24: 0.0287
Feature25: 0.0288
Feature26: 0.0289
Feature27: 0.0288
Feature28: 0.0287
Feature29: 0.0287
Feature30: 0.0287
Feature31: 0.0288
Feature32: 0.0290
Feature33: 0.0289
Feature34: 0.0287
Feature35: 0.0289
Feature36: 0.0289
Feature37: 0.0288
Feature38: 0.0288
Feature39: 0.0289
Feature40: 0.0289
Feature41: 0.0290
Feature42: 0.0289
Feature43: 0.0289
Feature44: 0.0290
Feature45: 0.0290
Feature46: 0.0289
Feature47: 0.0289
Feature48: 0.0289
Feature49: 0.0288
Feature50: 0.0290
Вільний член (intercept): 4.0993
Середньоквадратична помилка (MSE): 0.0100
Коефіцієнт детермінації (R²): 0.9924   
- **Коефіцієнти моделі**: Показують вагу кожної ознаки у лінійній регресії. Наприклад:
  - `Feature1: 0.5770` — коефіцієнт для першої ознаки, що відповідає масштабованому значенню (оригінальний коефіцієнт 2, але після масштабування він змінився).
  - `Feature2: 0.8658` — для другої ознаки (оригінальний коефіцієнт 3).
  - `Feature3: -0.4326` — для третьої ознаки (оригінальний коефіцієнт -1.5).
  - Для `Feature4`–`Feature50` коефіцієнти близькі до 0.0287–0.0290, що відповідає невеликому впливу.
- **Вільний член (intercept)**: 4.0993 — це зміщення моделі, яке враховує середнє значення цільової змінної після масштабування.
- **Середньоквадратична помилка (MSE)**: 0.0100 — середня квадратична різниця між фактичними та прогнозованими значеннями. Значення близьке до 0, що вказує на високу точність моделі.
- **Коефіцієнт детермінації (R²)**: 0.9924 — показує, що 99.24% варіації цільової змінної пояснюється моделлю. Це дуже високий показник, що свідчить про хорошу відповідність моделі даним.
![Фактичні vs Прогнозовані значення](https://github.com/KPILabWorks/Voronkova_Elizaveta_TV-21/blob/main/Pr5/Снимок%20экрана%202025-04-02%20в%2020.43.42.png?raw=true)

## Пояснення графіка:
- **Вісь X**: Фактичні значення цільової змінної (`y_test`).
- **Вісь Y**: Прогнозовані значення (`y_pred`).
- **Точки**: Кожна точка представляє пару (фактичне значення, прогнозоване значення) для одного зразка з тестової вибірки.
- **Червона пунктирна лінія**: Лінія \( y = x \), яка показує ідеальний випадок, коли прогнозовані значення дорівнюють фактичним.
- **Аналіз**: Точки щільно згруповані навколо червоної лінії, що вказує на високу точність моделі. Невеликий розкид пояснюється шумом у даних (додано через `np.random.normal`).
## Висновки
- Точки на графіку щільно згруповані навколо лінії \( y = x \), що підтверджує високу точність моделі.
- Розкид точок є мінімальним і пояснюється шумом у даних.
- Лінійна регресія добре впоралася із задачею, оскільки дані мають лінійну залежність.
- Масштабування ознак (`StandardScaler`) допомогло моделі коректно врахувати вплив усіх ознак.
